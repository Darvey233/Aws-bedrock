{"filter":false,"title":"temperature.py","tooltip":"/workshop/labs/temperature/temperature.py","undoManager":{"mark":2,"position":2,"stack":[[{"start":{"row":0,"column":0},"end":{"row":3,"column":0},"action":"insert","lines":["import sys","from langchain_community.llms import Bedrock","",""],"id":1}],[{"start":{"row":3,"column":0},"end":{"row":22,"column":0},"action":"insert","lines":["def get_text_response(input_content, temperature): #text-to-text client function","    ","    model_kwargs = { #AI21","        \"maxTokens\": 1024, ","        \"temperature\": temperature, ","        \"topP\": 0.5, ","        \"stopSequences\": [], ","        \"countPenalty\": {\"scale\": 0 }, ","        \"presencePenalty\": {\"scale\": 0 }, ","        \"frequencyPenalty\": {\"scale\": 0 } ","    }","    ","    llm = Bedrock( #create a Bedrock llm client","        model_id=\"ai21.j2-ultra-v1\",","        model_kwargs = model_kwargs","    )","    ","    return llm.invoke(input_content) #return a response to the prompt","",""],"id":2}],[{"start":{"row":22,"column":0},"end":{"row":26,"column":0},"action":"insert","lines":["for i in range(3):","    response = get_text_response(sys.argv[1], float(sys.argv[2]))","    print(response)","",""],"id":3}]]},"ace":{"folds":[],"scrolltop":64.2,"scrollleft":0,"selection":{"start":{"row":26,"column":0},"end":{"row":26,"column":0},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1716763961585,"hash":"13364bd85e93d2bd7dc61e27053d91cc2c8bddd5"}